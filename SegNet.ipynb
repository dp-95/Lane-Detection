{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nimport torch\nimport torchvision.transforms as transforms\nimport numpy as np\nfrom sklearn import preprocessing\n\nimport torch.nn as nn\nfrom torchvision import models\nimport torch.nn.functional as F\nimport operator\n\nimport time\nfrom torch.optim import lr_scheduler","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width = 256\nimg_height = 128\nimg_channel = 3\nlabel_width = 256\nlabel_height = 128\nlabel_channel = 1\nclass_num = 2 \n\ndata_loader_numworkers = 8\n\ntrain_path = \"/kaggle/input/trainset/trainset/train_index.txt\"\nval_path = \"/kaggle/input/trainset/trainset/val_index.txt\"\ntest_path = \"/kaggle/input/trainset/testset/test_index.txt\"\nsave_path = \"/kaggle/working/\"\n# pretrained_path = \"/content/93.21209738638905.pth\"\n\nclass_weight = [0.02, 1.02]\n\nseed = 69\nbatch_size = 15\ntest_batch_size = 1\nlr = 0.01\nepochs = 5\nlog_interval = 300","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def readTxt(file_path):\n\timg_list = []\n\twith open(file_path, 'r') as file_to_read:\n\t\twhile True:\n\t\t\tlines = file_to_read.readline()\n\t\t\tif not lines:\n\t\t\t\tbreak\n\t\t\titem = lines.strip().split()\n\t\t\timg_list.append(item)\n\tfile_to_read.close()\n\tfor i in range(len(img_list)):\n\t\tfor j in range(len(img_list[i])):\n\t\t\timg_list[i][j] = img_list[i][j].replace(\"D:/dataset\",\"/kaggle/input/trainset/trainset\")\n\treturn img_list\n\nclass RoadSequenceDataset(Dataset):\n\n\tdef __init__(self, file_path, transforms):\n\t\tself.img_list = readTxt(file_path)\n\t\tself.dataset_size = len(self.img_list)\n\t\tself.transforms = transforms\n\n\tdef __len__(self):\n\t\treturn self.dataset_size\n\n\tdef __getitem__(self, idx):\n\t\timg_path_list = self.img_list[idx]\n\t\tdata = Image.open(img_path_list[4])\n\t\tlabel = Image.open(img_path_list[5])\n\t\tdata = self.transforms(data)\n\t\tlabel = torch.squeeze(self.transforms(label))\n\t\tsample = {'data':data, 'label':label}\n\t\treturn sample","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed( seed )\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\" )\nop_transforms = transforms.Compose([transforms.ToTensor()])\ndevice","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(\n\tRoadSequenceDataset(\n\t\tfile_path  = train_path,\n\t\ttransforms = op_transforms),\n\t\tbatch_size = batch_size,\n\t\tshuffle = True,\n\t\tnum_workers = data_loader_numworkers\n\t)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loader = torch.utils.data.DataLoader(\n\tRoadSequenceDataset(\n\t\tfile_path  = val_path,\n\t\ttransforms = op_transforms),\n\t\tbatch_size = test_batch_size,\n\t\tshuffle = True,\n\t\tnum_workers = data_loader_numworkers\n\t)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_model():\n\tuse_cuda = torch.cuda.is_available()\n\tdevice = torch.device(\"cuda\" if use_cuda else \"cpu\" )\n\treturn SegNet().to(device)\n\nclass SegNet(nn.Module):\n\tdef __init__(self):\n\t\tsuper(SegNet,self).__init__()\n\t\tself.vgg16_bn = models.vgg16_bn().features\n\t\tself.relu = nn.ReLU(inplace=True)\n\t\tself.index_MaxPool = nn.MaxPool2d(\n\t\t\tkernel_size=2, stride=2, return_indices=True)\n\t\tself.index_UnPool = nn.MaxUnpool2d(\n\t\t\tkernel_size=2, stride=2)\n\t\tglobal class_num\n\n\t\tself.conv1_block = nn.Sequential( self.vgg16_bn[0],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[1],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[2],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[3],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[4],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[5]\n\t\t\t\t\t\t\t\t\t\t)\n\t\tself.conv2_block = nn.Sequential( self.vgg16_bn[7],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[8],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[9],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[10],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[11],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[12]\n\t\t\t\t\t\t\t\t\t\t)\n\t\tself.conv3_block = nn.Sequential( self.vgg16_bn[14],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[15],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[16],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[17],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[18],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[19],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[20],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[21],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[22]\n\t\t\t\t\t\t\t\t\t\t)\n\t\tself.conv4_block = nn.Sequential( self.vgg16_bn[24],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[25],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[26],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[27],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[28],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[29],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[30],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[31],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[32]\n\t\t\t\t\t\t\t\t\t\t)\n\t\tself.conv5_block = nn.Sequential( self.vgg16_bn[34],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[35],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[36],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[37],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[38],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[39],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[40],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[41],\n\t\t\t\t\t\t\t\t\t\tself.vgg16_bn[42]\n\t\t\t\t\t\t\t\t\t\t)\n\t\tself.upconv5_block = nn.Sequential(\n\t\t\tnn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\tnn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\tnn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\t)\n\t\tself.upconv4_block = nn.Sequential(\n\t\t\tnn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\tnn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\tnn.Conv2d(512, 256, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\t)\n\t\tself.upconv3_block = nn.Sequential(\n\t\t\tnn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\tnn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\tnn.Conv2d(256, 128, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\t)\n\t\tself.upconv2_block = nn.Sequential(\n\t\t\tnn.Conv2d(128, 128, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\tnn.Conv2d(128, 64, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\t)\n\t\tself.upconv1_block = nn.Sequential(\n\t\t\tnn.Conv2d(64, 64, kernel_size=(3,3), padding=(1,1)),\n\t\t\tnn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True),\n\t\t\tself.relu,\n\t\t\tnn.Conv2d(64, class_num, kernel_size=(3,3), padding=(1,1)),\n\t\t\t)\n\n\tdef forward(self, x):\n\t\tf1, idx1 = self.index_MaxPool(self.conv1_block(x))\n\t\tf2, idx2 = self.index_MaxPool(self.conv2_block(f1))\n\t\tf3, idx3 = self.index_MaxPool(self.conv3_block(f2))\n\t\tf4, idx4 = self.index_MaxPool(self.conv4_block(f3))\n\t\tf5, idx5 = self.index_MaxPool(self.conv5_block(f4))\n\t\tup6 = self.index_UnPool( f5, idx5 ) \n\t\tup5 = self.index_UnPool( self.upconv5_block(up6), idx4 )\n\t\tup4 = self.index_UnPool( self.upconv4_block(up5), idx3 )\n\t\tup3 = self.index_UnPool( self.upconv3_block(up4), idx2 )\n\t\tup2 = self.index_UnPool( self.upconv2_block(up3), idx1 )\n\t\tup1 = self.upconv1_block(up2)\n\n\t\treturn F.log_softmax( up1, dim=1)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SegNet()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"SegNet(\n  (vgg16_bn): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (26): ReLU(inplace=True)\n    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (36): ReLU(inplace=True)\n    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (39): ReLU(inplace=True)\n    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (relu): ReLU(inplace=True)\n  (index_MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (index_UnPool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n  (conv1_block): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n  )\n  (conv2_block): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n  )\n  (conv3_block): Sequential(\n    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n  )\n  (conv4_block): Sequential(\n    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n  )\n  (conv5_block): Sequential(\n    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n  )\n  (upconv5_block): Sequential(\n    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n  )\n  (upconv4_block): Sequential(\n    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n  )\n  (upconv3_block): Sequential(\n    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n  )\n  (upconv2_block): Sequential(\n    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n  )\n  (upconv1_block): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train( epoch, model, train_loader, device, optimizer, criterion ):\n\tsince = time.time()\n\tglobal log_interval\n\tmodel.train()\n\tfor batch_idx, sample_batched in enumerate(train_loader):\n\t\tdata = sample_batched['data'].to(device)\n\t\ttarget = sample_batched['label'].type(torch.LongTensor).to(device)\n\t\toptimizer.zero_grad()\n\t\toutput = model(data)\n\t\tloss = criterion( output, target )\n\t\tloss.backward()\n\t\toptimizer.step()\n\t\tif batch_idx % log_interval == 0:\n\t\t\tprint('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\ttime_elapsed = time.time() - since\n\tprint('Train Epoch: {} complete in {:.0f}m {:.0f}s'.format(epoch,\n        time_elapsed // 60, time_elapsed % 60))","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def val(model, val_loader, device, criterion, best_acc):\n  model.eval()\n  test_loss=0\n  correct=0\n  global test_batch_size\n  global label_height\n  global label_width\n  with torch.no_grad():\n    for sample_batched in val_loader:\n      data = sample_batched['data'].to(device)\n      target = sample_batched['label'].type(torch.LongTensor).to(device)\n      output = model(data)\n      test_loss += criterion(output,target).item()\n      pred = output.max(1,keepdim=True)[1]\n      correct += pred.eq(target.view_as(pred)).sum().item()\n    test_loss /= (len(val_loader)/test_batch_size)\n    val_acc = 100. * int(correct) / (len(val_loader.dataset)*label_width*label_height)\n    print('\\nAverage loss:{:.4f}, Accuracy:{}/{} ({:.5f}%\\n'.format(\n        test_loss, int(correct), len(val_loader.dataset), val_acc\n    ))\n    torch.save(model.state_dict(),'%s.pth'%val_acc)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = generate_model()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr )\nscheduler = lr_scheduler.StepLR( optimizer, step_size=1, gamma=0.5)\nclass_weight = torch.Tensor(class_weight)\ncriterion = torch.nn.CrossEntropyLoss(weight=class_weight).to(device)\nbest_acc = 0","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(epochs):\n\tscheduler.step()\n\ttrain(epoch, model, train_loader, device, optimizer, criterion )\n\tval(model, val_loader, device, criterion, best_acc )","execution_count":12,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"Train Epoch: 0 [0/91660 (0%)]\tLoss: 0.743935\nTrain Epoch: 0 [4500/91660 (5%)]\tLoss: 0.391666\nTrain Epoch: 0 [9000/91660 (10%)]\tLoss: 0.409659\nTrain Epoch: 0 [13500/91660 (15%)]\tLoss: 0.358834\nTrain Epoch: 0 [18000/91660 (20%)]\tLoss: 0.346314\nTrain Epoch: 0 [22500/91660 (25%)]\tLoss: 0.319132\nTrain Epoch: 0 [27000/91660 (29%)]\tLoss: 0.310673\nTrain Epoch: 0 [31500/91660 (34%)]\tLoss: 0.218522\nTrain Epoch: 0 [36000/91660 (39%)]\tLoss: 0.189994\nTrain Epoch: 0 [40500/91660 (44%)]\tLoss: 0.206519\nTrain Epoch: 0 [45000/91660 (49%)]\tLoss: 0.182008\nTrain Epoch: 0 [49500/91660 (54%)]\tLoss: 0.172541\nTrain Epoch: 0 [54000/91660 (59%)]\tLoss: 0.147336\nTrain Epoch: 0 [58500/91660 (64%)]\tLoss: 0.168500\nTrain Epoch: 0 [63000/91660 (69%)]\tLoss: 0.170218\nTrain Epoch: 0 [67500/91660 (74%)]\tLoss: 0.156185\nTrain Epoch: 0 [72000/91660 (79%)]\tLoss: 0.149233\nTrain Epoch: 0 [76500/91660 (83%)]\tLoss: 0.169942\nTrain Epoch: 0 [81000/91660 (88%)]\tLoss: 0.141467\nTrain Epoch: 0 [85500/91660 (93%)]\tLoss: 0.137850\nTrain Epoch: 0 [90000/91660 (98%)]\tLoss: 0.141501\nTrain Epoch: 0 complete in 17m 53s\n\nAverage loss:0.1668, Accuracy:342495113/11457 (91.22913%\n\nTrain Epoch: 1 [0/91660 (0%)]\tLoss: 0.133087\nTrain Epoch: 1 [4500/91660 (5%)]\tLoss: 0.105184\nTrain Epoch: 1 [9000/91660 (10%)]\tLoss: 0.126537\nTrain Epoch: 1 [13500/91660 (15%)]\tLoss: 0.135088\nTrain Epoch: 1 [18000/91660 (20%)]\tLoss: 0.128993\nTrain Epoch: 1 [22500/91660 (25%)]\tLoss: 0.107071\nTrain Epoch: 1 [27000/91660 (29%)]\tLoss: 0.121258\nTrain Epoch: 1 [31500/91660 (34%)]\tLoss: 0.129991\nTrain Epoch: 1 [36000/91660 (39%)]\tLoss: 0.113382\nTrain Epoch: 1 [40500/91660 (44%)]\tLoss: 0.102426\nTrain Epoch: 1 [45000/91660 (49%)]\tLoss: 0.132014\nTrain Epoch: 1 [49500/91660 (54%)]\tLoss: 0.140510\nTrain Epoch: 1 [54000/91660 (59%)]\tLoss: 0.127353\nTrain Epoch: 1 [58500/91660 (64%)]\tLoss: 0.110061\nTrain Epoch: 1 [63000/91660 (69%)]\tLoss: 0.113609\nTrain Epoch: 1 [67500/91660 (74%)]\tLoss: 0.100148\nTrain Epoch: 1 [72000/91660 (79%)]\tLoss: 0.100290\nTrain Epoch: 1 [76500/91660 (83%)]\tLoss: 0.100638\nTrain Epoch: 1 [81000/91660 (88%)]\tLoss: 0.108155\nTrain Epoch: 1 [85500/91660 (93%)]\tLoss: 0.105800\nTrain Epoch: 1 [90000/91660 (98%)]\tLoss: 0.118996\nTrain Epoch: 1 complete in 17m 51s\n\nAverage loss:0.1367, Accuracy:351604505/11457 (93.65556%\n\nTrain Epoch: 2 [0/91660 (0%)]\tLoss: 0.120292\nTrain Epoch: 2 [4500/91660 (5%)]\tLoss: 0.098043\nTrain Epoch: 2 [9000/91660 (10%)]\tLoss: 0.101464\nTrain Epoch: 2 [13500/91660 (15%)]\tLoss: 0.100880\nTrain Epoch: 2 [18000/91660 (20%)]\tLoss: 0.091796\nTrain Epoch: 2 [22500/91660 (25%)]\tLoss: 0.107059\nTrain Epoch: 2 [27000/91660 (29%)]\tLoss: 0.106819\nTrain Epoch: 2 [31500/91660 (34%)]\tLoss: 0.098633\nTrain Epoch: 2 [36000/91660 (39%)]\tLoss: 0.089639\nTrain Epoch: 2 [40500/91660 (44%)]\tLoss: 0.094971\nTrain Epoch: 2 [45000/91660 (49%)]\tLoss: 0.093496\nTrain Epoch: 2 [49500/91660 (54%)]\tLoss: 0.102910\nTrain Epoch: 2 [54000/91660 (59%)]\tLoss: 0.107754\nTrain Epoch: 2 [58500/91660 (64%)]\tLoss: 0.092253\nTrain Epoch: 2 [63000/91660 (69%)]\tLoss: 0.106769\nTrain Epoch: 2 [67500/91660 (74%)]\tLoss: 0.084976\nTrain Epoch: 2 [72000/91660 (79%)]\tLoss: 0.090473\nTrain Epoch: 2 [76500/91660 (83%)]\tLoss: 0.106499\nTrain Epoch: 2 [81000/91660 (88%)]\tLoss: 0.098692\nTrain Epoch: 2 [85500/91660 (93%)]\tLoss: 0.098567\nTrain Epoch: 2 [90000/91660 (98%)]\tLoss: 0.106721\nTrain Epoch: 2 complete in 17m 54s\n\nAverage loss:0.1513, Accuracy:355621589/11457 (94.72558%\n\nTrain Epoch: 3 [0/91660 (0%)]\tLoss: 0.093435\nTrain Epoch: 3 [4500/91660 (5%)]\tLoss: 0.081609\nTrain Epoch: 3 [9000/91660 (10%)]\tLoss: 0.094460\nTrain Epoch: 3 [13500/91660 (15%)]\tLoss: 0.082533\nTrain Epoch: 3 [18000/91660 (20%)]\tLoss: 0.087946\nTrain Epoch: 3 [22500/91660 (25%)]\tLoss: 0.084820\nTrain Epoch: 3 [27000/91660 (29%)]\tLoss: 0.088003\nTrain Epoch: 3 [31500/91660 (34%)]\tLoss: 0.080723\nTrain Epoch: 3 [36000/91660 (39%)]\tLoss: 0.090794\nTrain Epoch: 3 [40500/91660 (44%)]\tLoss: 0.091183\nTrain Epoch: 3 [45000/91660 (49%)]\tLoss: 0.079424\nTrain Epoch: 3 [49500/91660 (54%)]\tLoss: 0.081934\nTrain Epoch: 3 [54000/91660 (59%)]\tLoss: 0.088526\nTrain Epoch: 3 [58500/91660 (64%)]\tLoss: 0.080669\nTrain Epoch: 3 [63000/91660 (69%)]\tLoss: 0.081167\nTrain Epoch: 3 [67500/91660 (74%)]\tLoss: 0.080210\nTrain Epoch: 3 [72000/91660 (79%)]\tLoss: 0.081496\nTrain Epoch: 3 [76500/91660 (83%)]\tLoss: 0.090749\nTrain Epoch: 3 [81000/91660 (88%)]\tLoss: 0.087459\nTrain Epoch: 3 [85500/91660 (93%)]\tLoss: 0.084695\nTrain Epoch: 3 [90000/91660 (98%)]\tLoss: 0.084065\nTrain Epoch: 3 complete in 17m 51s\n\nAverage loss:0.1999, Accuracy:357694186/11457 (95.27765%\n\nTrain Epoch: 4 [0/91660 (0%)]\tLoss: 0.074851\nTrain Epoch: 4 [4500/91660 (5%)]\tLoss: 0.086220\nTrain Epoch: 4 [9000/91660 (10%)]\tLoss: 0.073410\nTrain Epoch: 4 [13500/91660 (15%)]\tLoss: 0.087383\nTrain Epoch: 4 [18000/91660 (20%)]\tLoss: 0.069129\nTrain Epoch: 4 [22500/91660 (25%)]\tLoss: 0.079567\nTrain Epoch: 4 [27000/91660 (29%)]\tLoss: 0.073236\nTrain Epoch: 4 [31500/91660 (34%)]\tLoss: 0.077076\nTrain Epoch: 4 [36000/91660 (39%)]\tLoss: 0.078841\nTrain Epoch: 4 [40500/91660 (44%)]\tLoss: 0.069410\nTrain Epoch: 4 [45000/91660 (49%)]\tLoss: 0.074562\nTrain Epoch: 4 [49500/91660 (54%)]\tLoss: 0.068561\nTrain Epoch: 4 [54000/91660 (59%)]\tLoss: 0.067443\nTrain Epoch: 4 [58500/91660 (64%)]\tLoss: 0.070964\nTrain Epoch: 4 [63000/91660 (69%)]\tLoss: 0.079771\nTrain Epoch: 4 [67500/91660 (74%)]\tLoss: 0.065590\nTrain Epoch: 4 [72000/91660 (79%)]\tLoss: 0.076229\nTrain Epoch: 4 [76500/91660 (83%)]\tLoss: 0.071110\nTrain Epoch: 4 [81000/91660 (88%)]\tLoss: 0.086691\nTrain Epoch: 4 [85500/91660 (93%)]\tLoss: 0.071804\nTrain Epoch: 4 [90000/91660 (98%)]\tLoss: 0.076566\nTrain Epoch: 4 complete in 17m 51s\n\nAverage loss:0.2448, Accuracy:359246714/11457 (95.69119%\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def readTxtTest(file_path):\n\timg_list = []\n\twith open(file_path, 'r') as file_to_read:\n\t\twhile True:\n\t\t\tlines = file_to_read.readline()\n\t\t\tif not lines:\n\t\t\t\tbreak\n\t\t\titem = lines.strip().split()\n\t\t\timg_list.append(item)\n\tfile_to_read.close()\n\tfor i in range(len(img_list)):\n\t\tfor j in range(len(img_list[i])):\n\t\t\timg_list[i][j] = img_list[i][j].replace(\"D:/dataset\",\"/kaggle/input/testset/testset)\n\treturn img_list\n\nclass RoadSequenceDatasetTest(Dataset):\n\n\tdef __init__(self, file_path, transforms):\n\t\tself.img_list = readTxtTest(file_path)\n\t\tself.dataset_size = len(self.img_list)\n\t\tself.transforms = transforms\n\n\tdef __len__(self):\n\t\treturn self.dataset_size\n\n\tdef __getitem__(self, idx):\n\t\timg_path_list = self.img_list[idx]\n\t\tdata = Image.open(img_path_list[0])\n\t\tlabel = Image.open(img_path_list[1])\n\t\tdata = self.transforms(data)\n\t\tlabel = torch.squeeze(self.transforms(label))\n\t\tsample = {'data':data, 'label':label}\n\t\treturn sample","execution_count":13,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"EOL while scanning string literal (<ipython-input-13-d09c189fd8a5>, line 13)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-d09c189fd8a5>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    img_list[i][j] = img_list[i][j].replace(\"D:/dataset\",\"/kaggle/input/testset/testset)\u001b[0m\n\u001b[0m                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = torch.utils.data.DataLoader(\n\tRoadSequenceDatasetTest(\n\t\tfile_path  = test_path,\n\t\ttransforms = op_transforms),\n\t\tbatch_size = test_batch_size,\n\t\tshuffle = True,\n\t\tnum_workers = data_loader_numworkers\n\t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def output_result(model, test_loader, device):\n    model.eval()\n    k = 0\n    feature_dic=[]\n    with torch.no_grad():\n        for sample_batched in test_loader:\n            k+=1\n            data, target = sample_batched['data'].to(device), sample_batched['label'].type(torch.LongTensor).to(device)\n            output = model(data)\n            pred = output.max(1, keepdim=True)[1]\n            img = torch.squeeze(pred).cpu().unsqueeze(2).expand(-1,-1,3).numpy()*255\n            img = Image.fromarray(img.astype(np.uint8))\n            data = torch.squeeze(data).cpu().numpy()\n            data = np.transpose(data, [1,2,0]) * 255\n            data = Image.fromarray(data.astype(np.uint8))\n            org = data.copy()\n            rows = img.size[0]\n            cols = img.size[1]\n            for i in range(0, rows):\n                for j in range(0, cols):\n                    img2 = (img.getpixel((i, j)))\n                    if (img2[0] > 200 or img2[1] > 200 or img2[2] > 200):\n                        data.putpixel((i, j), (234, 53, 57, 255))\n            data = data.convert(\"RGB\")\n            org = org.convert(\"RGB\")\n            display(org, data)\n            # data.save(save_path + \"%s_data.jpg\" % k)#red line on the original image\n            # img.save(save_path + \"%s_pred.jpg\" % k)#prediction result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output_result(model, test_loader, device)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}